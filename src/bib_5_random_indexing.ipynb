{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy \n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip,os,glob\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_vector(dimensions,seed):\n",
    "    arr = np.array([0] * (dimensions-seed) + [1] * int(seed/2) + [-1] * int(seed/2) )\n",
    "    np.random.shuffle(arr)\n",
    "    return(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "textz=[]\n",
    "word_vec=dict()\n",
    "word_docz=dict()\n",
    "dimensions=500\n",
    "seed=8\n",
    "\n",
    "with open('../data/after_nltk/df_content_after_nltk+titles.csv', newline='', encoding=\"utf8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile) \n",
    "    for row in reader:\n",
    "        textz.append(row['content'].lower())\n",
    "        #if int(row['id'])>5000:\n",
    "        #    break\n",
    "        if int(row['id'])%1000==0:\n",
    "            print(row['id'])\n",
    "        current_doc_wordz=dict()\n",
    "        content=row['content'].lower()\n",
    "        for word in re.split('[\\W]', content):\n",
    "            if word not in current_doc_wordz:\n",
    "                current_doc_wordz[word]=1\n",
    "                try:\n",
    "                    word_docz[word]=word_docz[word]+1\n",
    "                except:\n",
    "                    word_docz[word]=1\n",
    "                    word_vec[word]=generate_random_vector(dimensions,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsingular_wordz = dict((k, v) for k, v in word_docz.items() if v > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_factor=1/sum(nonsingular_wordz.values())\n",
    "for k in nonsingular_wordz:\n",
    "    nonsingular_wordz[k]*=normalize_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000002376"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(nonsingular_wordz.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18143"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec=np.ones((len(textz),dimensions))\n",
    "line_id=0\n",
    "for text in textz:\n",
    "    for word in re.split('[\\W]',text):\n",
    "        if word in nonsingular_wordz:\n",
    "            doc_vec[line_id] = ( word_vec[word] / (nonsingular_wordz[word]) ) + doc_vec[line_id]\n",
    "    line_id=line_id+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Instead of doc_vec[text_id] = doc_vec[text_id] + word_vec[word] You will simply have a SECOND PASS loop in which You'll do something like word_vec[word] = word_vec[word] + doc_vec[doc_id]</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # returning the document vectors back into wordvectors\n",
    "# word_vec_loop =()\n",
    "# for word in word_vec:\n",
    "#     word_vec_loop[word] = word_vec[word] + doc_vec[line_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rerunning the loop with new word_vectors\n",
    "# doc_vec=np.ones((len(textz),dimensions))\n",
    "# line_id=0\n",
    "# for text in textz:\n",
    "#     for word in re.split('[\\W]',text):\n",
    "#         if word in nonsingular_wordz:\n",
    "#             doc_vec_loop[line_id] = ( word_vec_loop[word] / (nonsingular_wordz[word]) ) + doc_vec[line_id]\n",
    "#     line_id=line_id+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def nearest_neighbor(query_id,database):\n",
    "    query=database[query_id]\n",
    "    closest = distance.cdist([query], database, 'cosine')\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418 schulbucharbeit geschichtslehrbuch unterrichtspraxis trotzen zunehmend konkurrenz gelten schulbuch leitmedium geschichtsunterrichts manchmal behaupten modern schulbuecher selbstlaeufer verfuegen ueber zahlreiche methodenseiten bieten tipps unterrichtsgestaltung gut geschichtsunterricht moeglich lehrerinnen lehrer intensiv medial eigenlogik schulbuchs auseinandersetzen entstehen schulbuecher aufbauen zeichnen gutes schulbuch methoden schulbucharbeit eignen fuer reflektieren lehrlernprozesse vorliegend band geben zentrale fragen antwort erste umfassend monografie thema\n",
      "6044 0.7254626125352617 schulbuch internet bildungspolitik konsequenzen schulbuch leitmedium rolle staates schulbildung pisatests setzen schulen druck internet verbunden medialkulturelle wandel zwingen reaktion bislang bestimmen klassische schulbuch leitmedium unterricht inhalte medium staat bildungskanon unterrichtsdiskurs zentral steuern einfluss schwinden durchsetzung internets massenmedium zusehends nie können schueler schnell einfach wissen abfragen heute netz erlauben zudem umsetzung paedagogisch gefordert offen unterrichtsformen projektarbeit sowie training kompetenzen anhand verschieden onlineangebote ua wikipedia untersuchen andreas hiller position schulbuches leitmedium veraendert entwicklung hintergrund konzepte sicherheitsdispositiv gouvernementaler regierungsformen michel foucault eroertert deutlich steigend beduerfnis qualitativ gesichert orientierungswissen notwendigkeit dafuer geeignet definieren kriterien geprueften bildungsmediums verbinden buch plaedoyer fuer staerkung staatlich wissenspolitik fuer staatlich legitimiert orientierungsmedium schulbuch\n"
     ]
    }
   ],
   "source": [
    "import numpy.ma as ma\n",
    "\n",
    "query_id=418\n",
    "nns=nearest_neighbor(query_id,doc_vec)\n",
    "nn_id=np.argmin(ma.masked_where(nns<0.0000000001, nns))\n",
    "print(query_id,textz[query_id])\n",
    "print(nn_id,nns[0][nn_id],textz[nn_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Compute Cosine Similarity through dot product</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "nrm = Normalizer('l2')\n",
    "\n",
    "doc_vec_normed = nrm.fit_transform(doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/after_nltk/data_after_nltk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity:\n",
      "0.4470446064301517\n",
      "\n",
      "Title 1:\n",
      " grundgebiete der elektrotechnik band 2 zeitabhängige vorgänge\n",
      "\n",
      "Abstract 1:\n",
      "grundgebiete elektrotechnik band 2 zeitabhängige vorgänge band erfolgreich lehrbuches elektrotechnik behandeln zeitabhaengigen vorgaenge elektrisch magnetischen feldern sowie netzwerken stationaeren vorgaenge band beschreiben band enthaelt ergaenzende vertiefend aufgabensammlung modern lehrbuch bieten didaktisch ausgefeilt darstellung umfangreich stoffes geben leser optimale lernhilfen angabe lernziele durchgerechnet beispiele bungsaufgaben loesungen viel kontrollfragen wichtig fachausdruecke englisch version angeben bezug praxis beschreibung unterschiedlich anwendungen zahlreich fachgebieten elektrotechnik staendig herstellen dadurch motivation lernend verstaerkt buch wenden studierend elektrotechnik saemtlicher fachrichtungen technisch hochschulen universitaeten sowohl begleittext vorlesungen selbststudium eignen\n",
      "\n",
      "Title 2:\n",
      " grundgebiete der elektrotechnik band 1 stationäre vorgänge\n",
      "\n",
      "Abstract 2:\n",
      "grundgebiete elektrotechnik band 1 stationäre vorgänge bewaehrte dreibaendige werk stellen grundlagen elektrotechnik umfassen systematisch dar studierend elektrotechnik lehrbuch dienen ingenieuren technikern praxis leitfaden nachschlagewerk band behandeln stationaere vorgaenge elektrisch stromkreisen sowie elektrisch magnetischen feldern dabei beruecksichtigt mathematisch kenntnisse studentin studenten allmaehlich zunehmen deshalb beginnen autoren elektrisch strom leitern elektrostatisch feld zeitabhaengigen vorgaenge elektrisch magnetischen feldern sowie netzwerken band beschreiben band enthaelt ergaenzende vertiefend aufgabensammlung didaktisch ausgefeilt darstellung umfangreich stoffes lernzielen durchgerechnet beispielen bungsaufgaben loesungen viel kontrollfragen geben leser optimale lernhilfen vermitteln solide wissensfundament staendige bezug praxis zahlreich fachgebieten elektrotechnik motivation studierend verstaerken\n"
     ]
    }
   ],
   "source": [
    "# choose example \n",
    "example = query_id\n",
    "title_1 = df['title'].iloc[example]\n",
    "abstract_1 = textz[example]\n",
    "# get example vector\n",
    "vec_1 = doc_vec_normed[example,:]\n",
    "\n",
    "# compute similarity\n",
    "sim = np.dot(doc_vec_normed[example+1:,:],vec_1)\n",
    "\n",
    "# find most similar document, see paper\n",
    "title_2 = df['title'].iloc[np.argmax(sim)+example+1]\n",
    "abstract_2 = textz[np.argmax(sim)+example+1]\n",
    "\n",
    "print('\\nSimilarity:')\n",
    "print(np.max(sim))\n",
    "print('\\nTitle 1:')\n",
    "print(title_1)\n",
    "print('\\nAbstract 1:')\n",
    "print(abstract_1)\n",
    "print('\\nTitle 2:')\n",
    "print(title_2)\n",
    "print('\\nAbstract 2:')\n",
    "print(abstract_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K nearest Neighbors</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " schulbucharbeit das geschichtslehrbuch in der unterrichtspraxis\n",
      "\n",
      "\n",
      "[0.27453739]\n",
      " das schulbuch zwischen internet und bildungspolitik konsequenzen für das schulbuch als leitmedium und die rolle des staates in der schulbildung\n",
      "[0.24831622]\n",
      " kursbuch geschichte neubearbeitung allgemeine ausgabe von der antike bis zur gegenwart schülerbuch\n",
      "[0.19637193]\n",
      " die grenzen europas die europäische union zwischen erweiterung und überdehnung\n",
      "[0.18055889]\n",
      " musikalische akustik ein handbuch\n",
      "[0.16898805]\n",
      " bildungsmedien online kostenloses lehrmaterial aus dem internet marktsichtung und empirische nutzungsanalyse\n",
      "[0.16492219]\n",
      " ernährungsökologie komplexen herausforderungen im bereich ernährung integrativ begegnen\n",
      "[0.16461432]\n",
      " portfolio kompetenzen standards neue wege in der lehrerbildung für berufsbildende schulen \n",
      "[0.16369007]\n",
      " erfolgreich mit den großen des marketings\n",
      "[0.1634436]\n",
      " die kritik stirners und die kritik an stirner deutschportugiesisches symposion im oktober 2008 an der universidade de lisboa und am goetheinstitut lissabon\n",
      "[0.16330588]\n",
      " bücherdämmerung über die zukunft der buchkultur\n"
     ]
    }
   ],
   "source": [
    "# compares similarity of two abstracts through dot product\n",
    "\n",
    "# validation_vector1 \n",
    "validation_vector1 = query_id\n",
    "val_abstract_1 = textz[validation_vector1]\n",
    "# get validation_vector1\n",
    "val_vec_1 = doc_vec_normed[validation_vector1,:]\n",
    "\n",
    "# compute similarity of all entities\n",
    "vec_temp = []\n",
    "for vec in doc_vec_normed:\n",
    "    i = np.dot(val_vec_1,vec)\n",
    "    vec_temp.append(i)\n",
    "\n",
    "# turn list into DataFrame\n",
    "df_vec_temp = pd.DataFrame(vec_temp)\n",
    "\n",
    "# Create new DataFrame for sorted sim-values\n",
    "df_vec_temp_sorted = df_vec_temp.copy()\n",
    "df_vec_temp_sorted.sort_values(by=[0],inplace = True, ascending=False)\n",
    "\n",
    "# Get list of indices\n",
    "lst_vec_temp_sorted = df_vec_temp_sorted.iloc[1:11,:].index.values.tolist()\n",
    "lst_vec_temp_sorted\n",
    "\n",
    "print(df['title'].iloc[validation_vector1])\n",
    "print('\\n')\n",
    "\n",
    "for i in lst_vec_temp_sorted:\n",
    "#    print('\\n')\n",
    "    print(df_vec_temp.iloc[i].values)\n",
    "    print(df['title'].iloc[i])\n",
    "#     print(textz[i])\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/after_nltk/doc_vec-200.npy', doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
