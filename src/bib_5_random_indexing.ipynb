{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy \n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip,os,glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "#import librosa\n",
    "from sklearn import *\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_vector(dimensions,seed):\n",
    "    arr = np.array([0] * (dimensions-seed) + [1] * int(seed/2) + [-1] * int(seed/2) )\n",
    "    np.random.shuffle(arr)\n",
    "    return(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "textz=[]\n",
    "word_vec=dict()\n",
    "word_docz=dict()\n",
    "dimensions=500\n",
    "seed=8\n",
    "\n",
    "with open(r'C:\\Users\\Johannes\\Documents\\Projekte\\Code\\udk_library_local/data_movies_content_after_nltk_rri.csv', newline='', encoding=\"utf8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile) \n",
    "    for row in reader:\n",
    "        textz.append(row['content'].lower())\n",
    "        #if int(row['id'])>5000:\n",
    "        #    break\n",
    "        if int(row['id'])%1000==0:\n",
    "            print(row['id'])\n",
    "        current_doc_wordz=dict()\n",
    "        content=row['content'].lower()\n",
    "        for word in re.split('[\\W]', content):\n",
    "            if word not in current_doc_wordz:\n",
    "                current_doc_wordz[word]=1\n",
    "                try:\n",
    "                    word_docz[word]=word_docz[word]+1\n",
    "                except:\n",
    "                    word_docz[word]=1\n",
    "                    word_vec[word]=generate_random_vector(dimensions,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19327"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we focus on words which occur in more than HAPAX_THRESHOLD and less than STOPWORD_THRESHOLD documents because they just bring noise in our vector space\n",
    "\n",
    "HAPAX_THRESHOLD=4\n",
    "STOPWORD_THRESHOLD=1000\n",
    "nonsingular_wordz = dict((k, v) for k, v in word_docz.items() if v > HAPAX_THRESHOLD and v<STOPWORD_THRESHOLD)\n",
    "\n",
    "\n",
    "#we create IDF (inverse-document frequency) weights\n",
    "normalize_factor=1 / sum(nonsingular_wordz.values())\n",
    "for k in nonsingular_wordz:\n",
    "    nonsingular_wordz[k]*=normalize_factor\n",
    "    #print(nonsingular_wordz[k],k)\n",
    "    \n",
    "len(nonsingular_wordz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand word 2 doc\n",
      "\n",
      "doc 2 word\n",
      "word 2 doc\n"
     ]
    }
   ],
   "source": [
    "#0th pass - from random word vectors to meaningful doc vectors\n",
    "print(\"rand word 2 doc\\n\")\n",
    "doc_vec=np.zeros((len(textz),dimensions))\n",
    "line_id=0\n",
    "for text in textz:\n",
    "    for word in re.split(' ',text):\n",
    "        if word in nonsingular_wordz:\n",
    "            #document vector is a linear combination of IDF-weighted word vectors which document contains\n",
    "            doc_vec[line_id] = ( word_vec[word] / (nonsingular_wordz[word]) ) + doc_vec[line_id]\n",
    "            #simplified version (withoug IDF-weighting)\n",
    "            #doc_vec[line_id] = word_vec[word]   + doc_vec[line_id]\n",
    "    line_id=line_id+1\n",
    " \n",
    "\n",
    "for i in range(len(doc_vec)):\n",
    "    doc_vec[i]=preprocessing.normalize(doc_vec[i].reshape(1,-1))\n",
    "\n",
    "    \n",
    "#from document vectors to word vectors\n",
    "print(\"doc 2 word\")\n",
    "word_vec2=dict()\n",
    "line_id=0\n",
    "for text in textz:\n",
    "    for word in re.split(' ',text):\n",
    "        if word in nonsingular_wordz:\n",
    "            #print(word)\n",
    "            if word in word_vec2:\n",
    "                word_vec2[word] +=  doc_vec[line_id] \n",
    "            else:\n",
    "                word_vec2[word]=np.array([0.0]*dimensions)\n",
    "                #print(str(word_vec2[word]))\n",
    "\n",
    "                #doc_vec[line_id][0:18149]\n",
    "    line_id=line_id+1\n",
    "\n",
    "    \n",
    "#normalize all word vectors\n",
    "for k in word_vec2.keys():\n",
    "    word_vec2[k]=preprocessing.normalize(word_vec2[k].reshape(1,-1))\n",
    "\n",
    "print(\"word 2 doc\")  \n",
    "#and to doc vectors again\n",
    "doc_vec2=np.zeros((len(textz),dimensions))\n",
    "line_id=0\n",
    "for text in textz:\n",
    "    for word in re.split('[\\W]',text):\n",
    "        if word in nonsingular_wordz:\n",
    "            #document vector is a linear combination of IDF-weighted word vectors which document contains\n",
    "            try:\n",
    "                doc_vec2[line_id] = ( word_vec2[word] / (nonsingular_wordz[word]) ) + doc_vec2[line_id]\n",
    "            except:\n",
    "                1\n",
    "    line_id=line_id+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2word 2\n",
      "word 2 doc 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(doc_vec)):\n",
    "    doc_vec2[i]=preprocessing.normalize(doc_vec2[i].reshape(1,-1))\n",
    "\n",
    "    \n",
    "#from document vectors to word vectors\n",
    "print(\"doc2word 2\")\n",
    "word_vec2=dict()\n",
    "line_id=0\n",
    "for text in textz:\n",
    "    for word in re.split(' ',text):\n",
    "        if word in nonsingular_wordz:\n",
    "            #print(word)\n",
    "            if word in word_vec2:\n",
    "                word_vec2[word] +=  doc_vec2[line_id] \n",
    "            else:\n",
    "                word_vec2[word]=np.array([0.0]*dimensions)\n",
    "                #print(str(word_vec2[word]))\n",
    "\n",
    "                #doc_vec[line_id][0:18149]\n",
    "    line_id=line_id+1\n",
    "\n",
    "    \n",
    "#normalize all word vectors\n",
    "for k in word_vec2.keys():\n",
    "    word_vec2[k]=preprocessing.normalize(word_vec2[k].reshape(1,-1))\n",
    "\n",
    "print(\"word 2 doc 2\")  \n",
    "#and to doc vectors again\n",
    "doc_vec2=np.zeros((len(textz),dimensions))\n",
    "line_id=0\n",
    "for text in textz:\n",
    "    for word in re.split('[\\W]',text):\n",
    "        if word in nonsingular_wordz:\n",
    "            #document vector is a linear combination of IDF-weighted word vectors which document contains\n",
    "            try:\n",
    "                doc_vec2[line_id] = ( word_vec2[word] / (nonsingular_wordz[word]) ) + doc_vec2[line_id]\n",
    "            except:\n",
    "                1\n",
    "    line_id=line_id+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def nearest_neighbor(query_id,database):\n",
    "    query=database[query_id]\n",
    "    closest = distance.cdist([query], database, 'cosine')\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420 poetologie erinnern ernst meister spätwerk büchnerpreisträger ernst meister gelten lyriker jahrhundert gedicht ußerstes vervollständigung sicht zug infragestellung möglichkeitsbedingung sprechen grenze zusammenhang sprachverlust vergessen hintergrund kommen akt erinnern vielzahl bezugnahmen tradition vollziehen bedeutung aneignung hölderlin dienen pflege gedächtnis selbstvergewisserung mensch tod gott nietzsche conditio conditio poetica basis einzelanalysen gedicht machen karin herrmann entwicklungslogik werk perspektive ernst meister\n",
      "12167 0.639871060223846 kreativität rückrufaktion kreativität lehren kulturwissenschaft alltag expertengremium möglichkeitsbedingung symbolkompetenter kreativindustrien kritikerinnen forderung kreativität gouvernementalen imperativ werk themaenheft fallstudium stadt kreativität kulturwissenschaft diskussionsschwerpunkt geniediskurs kreativitätsbegriff entstehungskontexte cultural studie identitätsrepräsentation internet kreativität fetischismus kulturvergleich kreativitätsmythen architekturhochschule\n"
     ]
    }
   ],
   "source": [
    "import numpy.ma as ma\n",
    "\n",
    "query_id=420\n",
    "nns=nearest_neighbor(query_id,doc_vec)\n",
    "nn_id=np.argmin(ma.masked_where(nns<0.0000000001, nns))\n",
    "print(query_id,textz[query_id])\n",
    "print(nn_id,nns[0][nn_id],textz[nn_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Compute Cosine Similarity through dot product</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "nrm = Normalizer('l2')\n",
    "\n",
    "doc_vec_normed = nrm.fit_transform(doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content_nltk</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aernout mik communitas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aernout mik communitas aernout mik zählt zu de...</td>\n",
       "      <td>print</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anton henning dt engl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anton henning dt engl die vorliegende publikat...</td>\n",
       "      <td>print</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>die feuchtwangers familie tradition und jüdis...</td>\n",
       "      <td>specht heike</td>\n",
       "      <td>die feuchtwangers familie tradition und jüdisc...</td>\n",
       "      <td>print</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grüne philosophie ein konservativer denkansatz</td>\n",
       "      <td>scruton roger</td>\n",
       "      <td>grüne philosophie ein konservativer denkansatz...</td>\n",
       "      <td>print</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>technische dokumentation im maschinen und anl...</td>\n",
       "      <td>schlagowski heinz</td>\n",
       "      <td>technische dokumentation im maschinen und anla...</td>\n",
       "      <td>print</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25587</th>\n",
       "      <td>jochen roller  let's dance! lecture  performance</td>\n",
       "      <td>Konzept und Leitung: Gabriele Brandstetter.</td>\n",
       "      <td>jochen roller  let's dance! lecture  performan...</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25588</th>\n",
       "      <td>ai weiwei - stimmen gegen das verstummen</td>\n",
       "      <td>ein Film von Birgit Adler-Conrad.</td>\n",
       "      <td>ai weiwei - stimmen gegen das verstummen der c...</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25589</th>\n",
       "      <td>new york tomorrow</td>\n",
       "      <td>réalisation: Yoann Le Gruiec. Scénario: Jean-M...</td>\n",
       "      <td>new york tomorrow die webdokumentation new yor...</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25590</th>\n",
       "      <td>hostess</td>\n",
       "      <td>ein Film von Rolf Römer. Mit: Annekathrin Bürg...</td>\n",
       "      <td>hostess eine hostess die seit zwei jahren mit ...</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25591</th>\n",
       "      <td>bruno peinado</td>\n",
       "      <td>réalisation: Thomas Lallier.</td>\n",
       "      <td>bruno peinado bruno peinado hat die plastische...</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25592 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                aernout mik communitas    \n",
       "1                                 anton henning dt engl    \n",
       "2       die feuchtwangers familie tradition und jüdis...   \n",
       "3         grüne philosophie ein konservativer denkansatz   \n",
       "4       technische dokumentation im maschinen und anl...   \n",
       "...                                                  ...   \n",
       "25587   jochen roller  let's dance! lecture  performance   \n",
       "25588           ai weiwei - stimmen gegen das verstummen   \n",
       "25589                                  new york tomorrow   \n",
       "25590                                            hostess   \n",
       "25591                                      bruno peinado   \n",
       "\n",
       "                                                  author  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                           specht heike   \n",
       "3                                          scruton roger   \n",
       "4                                      schlagowski heinz   \n",
       "...                                                  ...   \n",
       "25587        Konzept und Leitung: Gabriele Brandstetter.   \n",
       "25588                  ein Film von Birgit Adler-Conrad.   \n",
       "25589  réalisation: Yoann Le Gruiec. Scénario: Jean-M...   \n",
       "25590  ein Film von Rolf Römer. Mit: Annekathrin Bürg...   \n",
       "25591                       réalisation: Thomas Lallier.   \n",
       "\n",
       "                                            content_nltk medium  \n",
       "0      aernout mik communitas aernout mik zählt zu de...  print  \n",
       "1      anton henning dt engl die vorliegende publikat...  print  \n",
       "2      die feuchtwangers familie tradition und jüdisc...  print  \n",
       "3      grüne philosophie ein konservativer denkansatz...  print  \n",
       "4      technische dokumentation im maschinen und anla...  print  \n",
       "...                                                  ...    ...  \n",
       "25587  jochen roller  let's dance! lecture  performan...  movie  \n",
       "25588  ai weiwei - stimmen gegen das verstummen der c...  movie  \n",
       "25589  new york tomorrow die webdokumentation new yor...  movie  \n",
       "25590  hostess eine hostess die seit zwei jahren mit ...  movie  \n",
       "25591  bruno peinado bruno peinado hat die plastische...  movie  \n",
       "\n",
       "[25592 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/after_nltk/data_movies_after_nltk.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity:\n",
      "0.3601289397761542\n",
      "\n",
      "Title 1:\n",
      " kleines schopenhauerlexikon\n",
      "\n",
      "Abstract 1:\n",
      "poetologie erinnern ernst meister spätwerk büchnerpreisträger ernst meister gelten lyriker jahrhundert gedicht ußerstes vervollständigung sicht zug infragestellung möglichkeitsbedingung sprechen grenze zusammenhang sprachverlust vergessen hintergrund kommen akt erinnern vielzahl bezugnahmen tradition vollziehen bedeutung aneignung hölderlin dienen pflege gedächtnis selbstvergewisserung mensch tod gott nietzsche conditio conditio poetica basis einzelanalysen gedicht machen karin herrmann entwicklungslogik werk perspektive ernst meister\n",
      "\n",
      "Title 2:\n",
      " kreativität eine rückrufaktion \n",
      "\n",
      "Abstract 2:\n",
      "kreativität rückrufaktion kreativität lehren kulturwissenschaft alltag expertengremium möglichkeitsbedingung symbolkompetenter kreativindustrien kritikerinnen forderung kreativität gouvernementalen imperativ werk themaenheft fallstudium stadt kreativität kulturwissenschaft diskussionsschwerpunkt geniediskurs kreativitätsbegriff entstehungskontexte cultural studie identitätsrepräsentation internet kreativität fetischismus kulturvergleich kreativitätsmythen architekturhochschule\n"
     ]
    }
   ],
   "source": [
    "# choose example \n",
    "example = query_id\n",
    "title_1 = df['title'].iloc[example]\n",
    "abstract_1 = textz[example]\n",
    "# get example vector\n",
    "vec_1 = doc_vec_normed[example,:]\n",
    "\n",
    "# compute similarity\n",
    "sim = np.dot(doc_vec_normed[example+1:,:],vec_1)\n",
    "\n",
    "# find most similar document, see paper\n",
    "title_2 = df['title'].iloc[np.argmax(sim)+example+1]\n",
    "abstract_2 = textz[np.argmax(sim)+example+1]\n",
    "\n",
    "print('\\nSimilarity:')\n",
    "print(np.max(sim))\n",
    "print('\\nTitle 1:')\n",
    "print(title_1)\n",
    "print('\\nAbstract 1:')\n",
    "print(abstract_1)\n",
    "print('\\nTitle 2:')\n",
    "print(title_2)\n",
    "print('\\nAbstract 2:')\n",
    "print(abstract_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K nearest Neighbors</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " kleines schopenhauerlexikon\n",
      "\n",
      "\n",
      "[0.36012894]\n",
      " kreativität eine rückrufaktion \n",
      "[0.3242632]\n",
      " ganz ohr neue musik in der gehörbildung \n",
      "[0.29305201]\n",
      " besucherbindung im kulturbetrieb ein handbuch\n",
      "[0.28472913]\n",
      " seine welt wissen enzyklopädien in der frühen neuzeit \n",
      "[0.28127997]\n",
      " fahrleitungen elektrischer bahnen planung berechnung ausführung betrieb\n",
      "[0.27391364]\n",
      " der himmel ist kein ort roman\n",
      "[0.27080921]\n",
      " lucien clergue brasília clergue lucien brasilia eclergue lucien brasilia \n",
      "[0.24808826]\n",
      " transzendenz und negativität religionsphilosophische und ästhetische studien\n",
      "[0.2075674]\n",
      "cast.\n",
      "[0.19010765]\n",
      " das jüdische in den wochenzeitungen zeiz spiegell und stern 19461989 berichterstattung zwischen popularisierungsbemühung vereinnahmung und abwehr\n"
     ]
    }
   ],
   "source": [
    "# compares similarity of two abstracts through dot product\n",
    "\n",
    "# validation_vector1 \n",
    "validation_vector1 = query_id\n",
    "val_abstract_1 = textz[validation_vector1]\n",
    "# get validation_vector1\n",
    "val_vec_1 = doc_vec_normed[validation_vector1,:]\n",
    "\n",
    "# compute similarity of all entities\n",
    "vec_temp = []\n",
    "for vec in doc_vec_normed:\n",
    "    i = np.dot(val_vec_1,vec)\n",
    "    vec_temp.append(i)\n",
    "\n",
    "# turn list into DataFrame\n",
    "df_vec_temp = pd.DataFrame(vec_temp)\n",
    "\n",
    "# Create new DataFrame for sorted sim-values\n",
    "df_vec_temp_sorted = df_vec_temp.copy()\n",
    "df_vec_temp_sorted.sort_values(by=[0],inplace = True, ascending=False)\n",
    "\n",
    "# Get list of indices\n",
    "lst_vec_temp_sorted = df_vec_temp_sorted.iloc[1:11,:].index.values.tolist()\n",
    "lst_vec_temp_sorted\n",
    "\n",
    "print(df['title'].iloc[validation_vector1])\n",
    "print('\\n')\n",
    "\n",
    "for i in lst_vec_temp_sorted:\n",
    "#    print('\\n')\n",
    "    print(df_vec_temp.iloc[i].values)\n",
    "    print(df['title'].iloc[i])\n",
    "#     print(textz[i])\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/after_nltk/rri_docvecs_for_tsne', doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
